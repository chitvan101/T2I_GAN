{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de27a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"StackGAN.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
    "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29b407f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditioned by the text.\n",
    "def conditioning_augmentation(x):\n",
    "\t\"\"\"The mean_logsigma passed as argument is converted into the text conditioning variable.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The output of the text embedding passed through a FC layer with LeakyReLU non-linearity.\n",
    "\n",
    "\tReturns:\n",
    "\t \tc: The text conditioning variable after computation.\n",
    "\t\"\"\"\n",
    "\tmean = x[:, :128]\n",
    "\tlog_sigma = x[:, 128:]\n",
    "\n",
    "\tstddev = tf.math.exp(log_sigma)\n",
    "\tepsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\n",
    "\tc = mean + stddev * epsilon\n",
    "\treturn c\n",
    "\n",
    "def build_ca_network():\n",
    "\t\"\"\"Builds the conditioning augmentation network.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,)) #size of the vocabulary in the text data\n",
    "\tmls = Dense(256)(input_layer1)\n",
    "\tmls = LeakyReLU(alpha=0.2)(mls)\n",
    "\tca = Lambda(conditioning_augmentation)(mls)\n",
    "\treturn Model(inputs=[input_layer1], outputs=[ca]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c049059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpSamplingBlock(x, num_kernels):\n",
    "\t\"\"\"An Upsample block with Upsampling2D, Conv2D, BatchNormalization and a ReLU activation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The preceding layer as input.\n",
    "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
    "\n",
    "\tReturns:\n",
    "\t\tx: The final activation layer after the Upsampling block.\n",
    "\t\"\"\"\n",
    "\tx = UpSampling2D(size=(2,2))(x)\n",
    "\tx = Conv2D(num_kernels, kernel_size=(3,3), padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x) #prevent from mode collapse\n",
    "\tx = ReLU()(x)\n",
    "\treturn x\n",
    "\n",
    "\n",
    "def build_stage1_generator():\n",
    "\n",
    "\tinput_layer1 = Input(shape=(1024,))\n",
    "\tca = Dense(256)(input_layer1)\n",
    "\tca = LeakyReLU(alpha=0.2)(ca)\n",
    "\n",
    "\t# Obtain the conditioned text\n",
    "\tc = Lambda(conditioning_augmentation)(ca)\n",
    "\n",
    "\tinput_layer2 = Input(shape=(100,))\n",
    "\tconcat = Concatenate(axis=1)([c, input_layer2]) \n",
    "\n",
    "\tx = Dense(16384, use_bias=False)(concat) \n",
    "\tx = ReLU()(x)\n",
    "\tx = Reshape((4, 4, 1024), input_shape=(16384,))(x)\n",
    "\n",
    "\tx = UpSamplingBlock(x, 512) \n",
    "\tx = UpSamplingBlock(x, 256)\n",
    "\tx = UpSamplingBlock(x, 128)\n",
    "\tx = UpSamplingBlock(x, 64)   # upsampled our image to 64*64*3 \n",
    "\n",
    "\tx = Conv2D(3, kernel_size=3, padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = Activation('tanh')(x)\n",
    "\n",
    "\tstage1_gen = Model(inputs=[input_layer1, input_layer2], outputs=[x, ca]) \n",
    "\treturn stage1_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01984259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)       [(None, 1024)]               0         []                            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 256)                  262400    ['input_26[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 256)                  0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)           (None, 128)                  0         ['leaky_re_lu_20[0][0]']      \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 228)                  0         ['lambda_5[0][0]',            \n",
      " )                                                                   'input_27[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 16384)                3735552   ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)             (None, 16384)                0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 4, 4, 1024)           0         ['re_lu_17[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampli  (None, 8, 8, 1024)           0         ['reshape_3[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 8, 8, 512)            4718592   ['up_sampling2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 8, 8, 512)            2048      ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)             (None, 8, 8, 512)            0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_13 (UpSampli  (None, 16, 16, 512)          0         ['re_lu_18[0][0]']            \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 16, 16, 256)          1179648   ['up_sampling2d_13[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 16, 16, 256)          1024      ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)             (None, 16, 16, 256)          0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_14 (UpSampli  (None, 32, 32, 256)          0         ['re_lu_19[0][0]']            \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 32, 32, 128)          294912    ['up_sampling2d_14[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 32, 32, 128)          512       ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)             (None, 32, 32, 128)          0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampli  (None, 64, 64, 128)          0         ['re_lu_20[0][0]']            \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 64, 64, 64)           73728     ['up_sampling2d_15[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 64, 64, 64)           256       ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)             (None, 64, 64, 64)           0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 64, 64, 3)            1728      ['re_lu_21[0][0]']            \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 64, 64, 3)            0         ['conv2d_34[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10270400 (39.18 MB)\n",
      "Trainable params: 10268480 (39.17 MB)\n",
      "Non-trainable params: 1920 (7.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_stage1_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebaa99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(x, num_kernels, kernel_size=(4,4), strides=2, activation=True):\n",
    "\t\"\"\"A ConvBlock with a Conv2D, BatchNormalization and LeakyReLU activation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The preceding layer as input.\n",
    "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
    "\n",
    "\tReturns:\n",
    "\t\tx: The final activation layer after the ConvBlock block.\n",
    "\t\"\"\"\n",
    "\tx = Conv2D(num_kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\t\n",
    "\tif activation:\n",
    "\t\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\treturn x\n",
    "\n",
    "\n",
    "def build_embedding_compressor():\n",
    "    \"\"\"Build embedding compressor model\n",
    "    \"\"\"\n",
    "    input_layer1 = Input(shape=(1024,)) \n",
    "    x = Dense(128)(input_layer1)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer1], outputs=[x])\n",
    "    return model\n",
    "\n",
    "# the discriminator is fed with two inputs, the feature from Generator and the text embedding\n",
    "def build_stage1_discriminator():\n",
    "\t\"\"\"Builds the Stage 1 Discriminator that uses the 64x64 resolution images from the generator\n",
    "\tand the compressed and spatially replicated embedding.\n",
    "\n",
    "\tReturns:\n",
    "\t\tStage 1 Discriminator Model for StackGAN.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(64, 64, 3))  \n",
    "\n",
    "\tx = Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\tx = ConvBlock(x, 128)\n",
    "\tx = ConvBlock(x, 256)\n",
    "\tx = ConvBlock(x, 512)\n",
    "\n",
    "\t# Obtain the compressed and spatially replicated text embedding\n",
    "\tinput_layer2 = Input(shape=(4, 4, 128)) #2nd input to discriminator, text embedding\n",
    "\tconcat = concatenate([x, input_layer2])\n",
    "\n",
    "\tx1 = Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(concat)\n",
    "\tx1 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\tx1 = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\t# Flatten and add a FC layer to predict.\n",
    "\tx1 = Flatten()(x1)\n",
    "\tx1 = Dense(1)(x1)\n",
    "\tx1 = Activation('sigmoid')(x1)\n",
    "\n",
    "\tstage1_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x1])  \n",
    "\treturn stage1_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6588785d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)       [(None, 64, 64, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 32, 32, 64)           3072      ['input_28[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 32, 32, 64)           0         ['conv2d_35[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 16, 16, 128)          131072    ['leaky_re_lu_21[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 16, 16, 128)          512       ['conv2d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 16, 16, 128)          0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 8, 8, 256)            524288    ['leaky_re_lu_22[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 8, 8, 256)            1024      ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 8, 8, 256)            0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 4, 4, 512)            2097152   ['leaky_re_lu_23[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 4, 4, 512)            2048      ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 4, 4, 512)            0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 4, 4, 512)            0         ['leaky_re_lu_24[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 8192)                 0         ['leaky_re_lu_25[0][0]']      \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    8193      ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)       [(None, 4, 4, 128)]          0         []                            \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 1)                    0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2767361 (10.56 MB)\n",
      "Trainable params: 2765569 (10.55 MB)\n",
      "Non-trainable params: 1792 (7.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_stage1_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce73be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building GAN with Generator and Discriminator\n",
    "\n",
    "def build_adversarial(generator_model, discriminator_model):\n",
    "\t\"\"\"Stage 1 Adversarial model.\n",
    "\n",
    "\tArgs:\n",
    "\t\tgenerator_model: Stage 1 Generator Model\n",
    "\t\tdiscriminator_model: Stage 1 Discriminator Model\n",
    "\n",
    "\tReturns:\n",
    "\t\tAdversarial Model.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,))  \n",
    "\tinput_layer2 = Input(shape=(100,)) \n",
    "\tinput_layer3 = Input(shape=(4, 4, 128)) \n",
    "\n",
    "\tx, ca = generator_model([input_layer1, input_layer2]) #text,noise\n",
    "\n",
    "\tdiscriminator_model.trainable = False \n",
    "\n",
    "\tprobabilities = discriminator_model([x, input_layer3]) \n",
    "\tadversarial_model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=[probabilities, ca])\n",
    "\treturn adversarial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "917545e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_30 (InputLayer)       [(None, 1024)]               0         []                            \n",
      "                                                                                                  \n",
      " input_31 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " model_13 (Functional)       [(None, 64, 64, 3),          1027040   ['input_30[0][0]',            \n",
      "                              (None, 256)]                0          'input_31[0][0]']            \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)       [(None, 4, 4, 128)]          0         []                            \n",
      "                                                                                                  \n",
      " model_14 (Functional)       (None, 1)                    2767361   ['model_13[0][0]',            \n",
      "                                                                     'input_32[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13037761 (49.74 MB)\n",
      "Trainable params: 10268480 (39.17 MB)\n",
      "Non-trainable params: 2769281 (10.56 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ganstage1 = build_adversarial(generator, discriminator)\n",
    "ganstage1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d594f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_prefix():\n",
    "\tcheckpoint_dir = './training_checkpoints'\n",
    "\tcheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "\n",
    "\treturn checkpoint_prefix\n",
    "\n",
    "def adversarial_loss(y_true, y_pred):\n",
    "\tmean = y_pred[:, :128]\n",
    "\tls = y_pred[:, 128:]\n",
    "\tloss = -ls + 0.5 * (-1 + tf.math.exp(2.0 * ls) + tf.math.square(mean))\n",
    "\tloss = K.mean(loss)\n",
    "\treturn loss\n",
    "\n",
    "def normalize(input_image, real_image):\n",
    "\tinput_image = (input_image / 127.5) - 1\n",
    "\treal_image = (real_image / 127.5) - 1\n",
    "\n",
    "\treturn input_image, real_image\n",
    "\n",
    "def load_class_ids_filenames(class_id_path, filename_path):\n",
    "\twith open(class_id_path, 'rb') as file:\n",
    "\t\tclass_id = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\twith open(filename_path, 'rb') as file:\n",
    "\t\tfilename = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\treturn class_id, filename\n",
    "\n",
    "def load_text_embeddings(text_embeddings):\n",
    "\twith open(text_embeddings, 'rb') as file:\n",
    "\t\tembeds = pickle.load(file, encoding='latin1')\n",
    "\t\tembeds = np.array(embeds)\n",
    "\n",
    "\treturn embeds\n",
    "\n",
    "def load_bbox(data_path):\n",
    "\tbbox_path = data_path + '/bounding_boxes.txt'\n",
    "\timage_path = data_path + '/images.txt'\n",
    "\tbbox_df = pd.read_csv(bbox_path, delim_whitespace=True, header=None).astype(int)\n",
    "\tfilename_df = pd.read_csv(image_path, delim_whitespace=True, header=None)\n",
    "\n",
    "\tfilenames = filename_df[1].tolist()\n",
    "\tbbox_dict = {i[:-4]:[] for i in filenames[:2]}\n",
    "\n",
    "\tfor i in range(0, len(filenames)):\n",
    "\t\tbbox = bbox_df.iloc[i][1:].tolist()\n",
    "\t\tdict_key = filenames[i][:-4]\n",
    "\t\tbbox_dict[dict_key] = bbox\n",
    "\n",
    "\treturn bbox_dict\n",
    "\n",
    "def load_images(image_path, bounding_box, size):\n",
    "\t\"\"\"Crops the image to the bounding box and then resizes it.\n",
    "\t\"\"\"\n",
    "\timage = Image.open(image_path).convert('RGB')\n",
    "\tw, h = image.size\n",
    "\tif bounding_box is not None:\n",
    "\t\tr = int(np.maximum(bounding_box[2], bounding_box[3]) * 0.75)\n",
    "\t\tc_x = int((bounding_box[0] + bounding_box[2]) / 2)\n",
    "\t\tc_y = int((bounding_box[1] + bounding_box[3]) / 2)\n",
    "\t\ty1 = np.maximum(0, c_y - r)\n",
    "\t\ty2 = np.minimum(h, c_y + r)\n",
    "\t\tx1 = np.maximum(0, c_x - r)\n",
    "\t\tx2 = np.minimum(w, c_x + r)\n",
    "\t\timage = image.crop([x1, y1, x2, y2])\n",
    "\n",
    "\timage = image.resize(size, PIL.Image.BILINEAR)\n",
    "\treturn image\n",
    "\n",
    "def load_data(filename_path, class_id_path, dataset_path, embeddings_path, size):\n",
    "\t\"\"\"Loads the Dataset.\n",
    "\t\"\"\"\n",
    "\tdata_dir = \"D:/1-pipelined_topics/GAN_texttoimage/birds_implementation/birds\"\n",
    "\ttrain_dir = data_dir + \"/train\"\n",
    "\ttest_dir = data_dir + \"/test\"\n",
    "\tembeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\tembeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\tfilename_path_train = train_dir + \"/filenames.pickle\"\n",
    "\tfilename_path_test = test_dir + \"/filenames.pickle\"\n",
    "\tclass_id_path_train = train_dir + \"/class_info.pickle\"\n",
    "\tclass_id_path_test = test_dir + \"/class_info.pickle\"\n",
    "\tdataset_path = \"D:/1-pipelined_topics/GAN_texttoimage/birds_implementation/CUB_200_2011\"\n",
    "\tclass_id, filenames = load_class_ids_filenames(class_id_path, filename_path)\n",
    "\tembeddings = load_text_embeddings(embeddings_path)\n",
    "\tbbox_dict = load_bbox(dataset_path)\n",
    "\n",
    "\tx, y, embeds = [], [], []\n",
    "\n",
    "\tfor i, filename in enumerate(filenames):\n",
    "\t\tbbox = bbox_dict[filename]\n",
    "\n",
    "\t\ttry:\t\n",
    "\t\t\timage_path = f'{dataset_path}/images/{filename}.jpg'\n",
    "\t\t\timage = load_images(image_path, bbox, size)\n",
    "\t\t\te = embeddings[i, :, :]\n",
    "\t\t\tembed_index = np.random.randint(0, e.shape[0] - 1)\n",
    "\t\t\tembed = e[embed_index, :]\n",
    "\n",
    "\t\t\tx.append(np.array(image))\n",
    "\t\t\ty.append(class_id[i])\n",
    "\t\t\tembeds.append(embed)\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f'{e}')\n",
    "\t\n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\tembeds = np.array(embeds)\n",
    "\t\n",
    "\treturn x, y, embeds\n",
    "\n",
    "def save_image(file, save_path):\n",
    "\t\"\"\"Saves the image at the specified file path.\n",
    "\t\"\"\"\n",
    "\timage = plt.figure()\n",
    "\tax = image.add_subplot(1,1,1)\n",
    "\tax.imshow(file)\n",
    "\tax.axis(\"off\")\n",
    "\tplt.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "754969b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# StackGAN class\n",
    "############################################################\n",
    "\n",
    "class StackGanStage1(object):\n",
    "  \"\"\"StackGAN Stage 1 class.\"\"\"\n",
    "\n",
    "  data_dir = \"D:/1-pipelined_topics/GAN_texttoimage/birds_implementation/birds\"\n",
    "  train_dir = data_dir + \"/train\"\n",
    "  test_dir = data_dir + \"/test\"\n",
    "  embeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "  embeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "  filename_path_train = train_dir + \"/filenames.pickle\"\n",
    "  filename_path_test = test_dir + \"/filenames.pickle\"\n",
    "  class_id_path_train = train_dir + \"/class_info.pickle\"\n",
    "  class_id_path_test = test_dir + \"/class_info.pickle\"\n",
    "  dataset_path = \"D:/1-pipelined_topics/GAN_texttoimage/birds_implementation/CUB_200_2011\"\n",
    "  def __init__(self, epochs=500, z_dim=100, batch_size=64, enable_function=True, stage1_generator_lr=0.0002, stage1_discriminator_lr=0.0002):\n",
    "\t  self.epochs = epochs\n",
    "\t  self.z_dim = z_dim\n",
    "\t  self.enable_function = enable_function\n",
    "\t  self.stage1_generator_lr = stage1_generator_lr\n",
    "\t  self.stage1_discriminator_lr = stage1_discriminator_lr\n",
    "\t  self.image_size = 64\n",
    "\t  self.conditioning_dim = 128\n",
    "\t  self.batch_size = batch_size\n",
    "        \n",
    "\t  self.stage1_generator_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t  self.stage1_discriminator_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "        \n",
    "\t  self.stage1_generator = build_stage1_generator()\n",
    "\t  self.stage1_generator.compile(loss='mse', optimizer=self.stage1_generator_optimizer)\n",
    "\n",
    "\t  self.stage1_discriminator = build_stage1_discriminator()\n",
    "\t  self.stage1_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage1_discriminator_optimizer)\n",
    "\n",
    "\t  self.ca_network = build_ca_network()\n",
    "\t  self.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t  self.embedding_compressor = build_embedding_compressor()\n",
    "\t  self.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t  self.stage1_adversarial = build_adversarial(self.stage1_generator, self.stage1_discriminator)\n",
    "\t  self.stage1_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage1_generator_optimizer)\n",
    "\n",
    "\t  self.checkpoint1 = tf.train.Checkpoint(\n",
    "        \tgenerator_optimizer=self.stage1_generator_optimizer,\n",
    "        \tdiscriminator_optimizer=self.stage1_discriminator_optimizer,\n",
    "        \tgenerator=self.stage1_generator,\n",
    "        \tdiscriminator=self.stage1_discriminator)\n",
    "\n",
    "  def visualize_stage1(self):\n",
    "\t  \"\"\"Running Tensorboard visualizations.\n",
    "\t\t\"\"\"\n",
    "\t  tb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "\t  tb.set_model(self.stage1_generator)\n",
    "\t  tb.set_model(self.stage1_discriminator)\n",
    "\t  tb.set_model(self.ca_network)\n",
    "\t  tb.set_model(self.embedding_compressor)\n",
    "\n",
    "  def train_stage1(self):\n",
    "\t  \"\"\"Trains the stage1 StackGAN.\n",
    "    \"\"\"\n",
    "\t  x_train, y_train, train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n",
    "\n",
    "\t  x_test, y_test, test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
    "      dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(64, 64))\n",
    "\n",
    "\t  real = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
    "\t  fake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
    "\n",
    "\t  for epoch in range(self.epochs):\n",
    "\t\t  print(f'Epoch: {epoch}')\n",
    "\n",
    "\t\t  gen_loss = []\n",
    "\t\t  dis_loss = []\n",
    "\n",
    "\t\t  num_batches = int(x_train.shape[0] / self.batch_size)\n",
    "\n",
    "\t\t  for i in range(num_batches):\n",
    "\n",
    "\t\t    latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t    embedding_text = train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\t\t    compressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
    "\t\t    compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
    "\t\t    compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "\t\t    image_batch = x_train[i * self.batch_size:(i+1) * self.batch_size]\n",
    "\t\t    image_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "\t\t    gen_images, _ = self.stage1_generator.predict([embedding_text, latent_space])\n",
    "\n",
    "\t\t    discriminator_loss = self.stage1_discriminator.train_on_batch([image_batch, compressed_embedding], \n",
    "\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
    "\n",
    "\t\t    discriminator_loss_gen = self.stage1_discriminator.train_on_batch([gen_images, compressed_embedding],\n",
    "\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
    "\n",
    "\t\t    discriminator_loss_wrong = self.stage1_discriminator.train_on_batch([gen_images[: self.batch_size-1], compressed_embedding[1:]], \n",
    "\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size-1, 1)))\n",
    "\n",
    "\t\t    # Discriminator loss\n",
    "\t\t    d_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_wrong))\n",
    "\t\t    dis_loss.append(d_loss)\n",
    "\n",
    "\t\t    print(f'Discriminator Loss: {d_loss}')\n",
    "\n",
    "\t\t    # Generator loss\n",
    "\t\t    g_loss = self.stage1_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
    "\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
    "\n",
    "\t\t    print(f'Generator Loss: {g_loss}')\n",
    "\t\t    gen_loss.append(g_loss)\n",
    "\n",
    "\t\t    if epoch % 5 == 0:\n",
    "\t\t\t\t    latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t\t\t    embedding_batch = test_embeds[0 : self.batch_size]\n",
    "\t\t\t\t    gen_images, _ = self.stage1_generator.predict_on_batch([embedding_batch, latent_space])\n",
    "\n",
    "\t\t\t\t    for i, image in enumerate(gen_images[:10]):\n",
    "\t\t\t\t        save_image(image, f'test/gen_1_{epoch}_{i}')\n",
    "\n",
    "\t\t    if epoch % 25 == 0:\n",
    "\t\t      self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
    "\t\t      self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")\n",
    "\t\t      self.ca_network.save_weights('weights/stage1_ca.h5')\n",
    "\t\t      self.embedding_compressor.save_weights('weights/stage1_embco.h5')\n",
    "\t\t      self.stage1_adversarial.save_weights('weights/stage1_adv.h5')      \n",
    "\n",
    "\t  self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
    "\t  self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65e50e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filename_path_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m stage1 \u001b[38;5;241m=\u001b[39m StackGanStage1()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstage1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_stage1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36mStackGanStage1.train_stage1\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_stage1\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     62\u001b[0m \t  \u001b[38;5;124;03m\"\"\"Trains the stage1 StackGAN.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \t  x_train, y_train, train_embeds \u001b[38;5;241m=\u001b[39m load_data(filename_path\u001b[38;5;241m=\u001b[39m\u001b[43mfilename_path_train\u001b[49m, class_id_path\u001b[38;5;241m=\u001b[39mclass_id_path_train,\n\u001b[0;32m     65\u001b[0m       dataset_path\u001b[38;5;241m=\u001b[39mdataset_path, embeddings_path\u001b[38;5;241m=\u001b[39membeddings_path_train, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[0;32m     67\u001b[0m \t  x_test, y_test, test_embeds \u001b[38;5;241m=\u001b[39m load_data(filename_path\u001b[38;5;241m=\u001b[39mfilename_path_test, class_id_path\u001b[38;5;241m=\u001b[39mclass_id_path_test, \n\u001b[0;32m     68\u001b[0m       dataset_path\u001b[38;5;241m=\u001b[39mdataset_path, embeddings_path\u001b[38;5;241m=\u001b[39membeddings_path_test, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[0;32m     70\u001b[0m \t  real \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.9\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename_path_train' is not defined"
     ]
    }
   ],
   "source": [
    "stage1 = StackGanStage1()\n",
    "stage1.train_stage1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22a0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
